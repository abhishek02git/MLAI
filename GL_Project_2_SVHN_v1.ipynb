{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GL_Project_2_SVHN_v1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreatLearningAIML1/gurgaon-feb-batch-abhishek02git/blob/master/GL_Project_2_SVHN_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eElXpijvlH-",
        "colab_type": "code",
        "outputId": "b82ef562-1767-479f-fc7a-cd18711a3d64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "#download data file not found on local machine\n",
        "import glob\n",
        "if len(glob.glob('SVHN_single_grey1.h5'))==0:\n",
        "  ! wget 'http://h0.ai/static/SVHN_single_grey1.h5'\n",
        "! ls -al"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-26 09:17:05--  http://h0.ai/static/SVHN_single_grey1.h5\n",
            "Resolving h0.ai (h0.ai)... 207.180.211.174\n",
            "Connecting to h0.ai (h0.ai)|207.180.211.174|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 491644096 (469M) [application/octet-stream]\n",
            "Saving to: ‘SVHN_single_grey1.h5’\n",
            "\n",
            "SVHN_single_grey1.h 100%[===================>] 468.87M  9.17MB/s    in 78s     \n",
            "\n",
            "2019-08-26 09:18:23 (6.00 MB/s) - ‘SVHN_single_grey1.h5’ saved [491644096/491644096]\n",
            "\n",
            "total 480144\n",
            "drwxr-xr-x 1 root root      4096 Aug 26 09:17 .\n",
            "drwxr-xr-x 1 root root      4096 Aug 26 08:56 ..\n",
            "drwxr-xr-x 1 root root      4096 Aug 22 16:14 .config\n",
            "drwxr-xr-x 1 root root      4096 Aug 22 16:14 sample_data\n",
            "-rw-r--r-- 1 root root 491644096 Aug 17 17:30 SVHN_single_grey1.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F56Q5u1owddn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import h5py\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import backend as K\n",
        "#from tensorflow.compact.v1.keras.backend import K\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Activation, Input, Flatten, Reshape, MaxPool2D, BatchNormalization \n",
        "\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam,Adagrad\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa4YVJv4x0eu",
        "colab_type": "code",
        "outputId": "dcc68ba4-2eba-41da-8269-6e82c7837be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "#Load and Prepare Data\n",
        "dset = h5py.File('SVHN_single_grey1.h5','r')\n",
        "X_train = np.array(dset['X_train'])\n",
        "X_test = np.array(dset['X_test'])\n",
        "X_val = np.array(dset['X_val'])\n",
        "y_train = np.array(dset['y_train'])\n",
        "y_test  = np.array(dset['y_test'])\n",
        "y_val = np.array(dset['y_val'])\n",
        "\n",
        "print (\"Training \", X_train.shape)\n",
        "print (\"Testing \", X_test.shape)\n",
        "print (\"Validation \", X_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training  (42000, 32, 32)\n",
            "Testing  (18000, 32, 32)\n",
            "Validation  (60000, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hb-xwiYWwVz3",
        "colab": {}
      },
      "source": [
        "# Prepare data for NN training\n",
        "X_train_nn = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
        "X_test_nn = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
        "X_val_nn = X_val.reshape(X_val.shape[0],X_train.shape[1],X_val.shape[2],1)\n",
        "y_train_nn = keras.utils.to_categorical(y_train)\n",
        "y_test_nn  = keras.utils.to_categorical(y_test)\n",
        "y_val_nn = keras.utils.to_categorical(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MugPYKh_bRJr",
        "colab_type": "code",
        "outputId": "f00fc9bb-137b-4654-a70e-b322d412a965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "source": [
        "# Implement KNN\n",
        "from sklearn.metrics import classification_report \n",
        "X_train_flat = X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2])\n",
        "X_test_flat = X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2])\n",
        "print (\"Running KNN on K = 25\")\n",
        "knn = KNeighborsClassifier(n_neighbors = 25,n_jobs=-1)\n",
        "knn.fit(X_train_flat,y_train)\n",
        "y_pred = knn.predict(X_test_flat)\n",
        "score = metrics.accuracy_score(y_test,y_pred)\n",
        "print (\"Accuracy Score\", score)\n",
        "print (\"Classification Report at K =25\")\n",
        "print (classification_report(y_test,y_pred))\n",
        "\n",
        "# Did not run KNN for multiple values as this was very slow. Its took 30+ mins for one K value"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running KNN on K = 25\n",
            "Accuracy Score 0.5296666666666666\n",
            "Classification Report at K =25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.71      0.55      1814\n",
            "           1       0.46      0.73      0.56      1828\n",
            "           2       0.63      0.54      0.58      1803\n",
            "           3       0.46      0.42      0.44      1719\n",
            "           4       0.64      0.65      0.65      1812\n",
            "           5       0.52      0.39      0.45      1768\n",
            "           6       0.50      0.41      0.45      1832\n",
            "           7       0.71      0.63      0.67      1808\n",
            "           8       0.47      0.37      0.41      1812\n",
            "           9       0.55      0.44      0.49      1804\n",
            "\n",
            "    accuracy                           0.53     18000\n",
            "   macro avg       0.54      0.53      0.52     18000\n",
            "weighted avg       0.54      0.53      0.53     18000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "61071125-1e2d-41da-9890-a27377d6fd75",
        "id": "GcIFF2ohwVG6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "print (y_train_nn[11])\n",
        "plt.imshow(X_train_nn[11].reshape(32,32),cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f33cca4cc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxC9Epkj8QmSKxC9Epkj8QmTK/wEl+gyjD/vUPgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cT5v29SWmGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network parameters\n",
        "latent_dim = 1000\n",
        "input_shape = (32,32,1)\n",
        "kernal_size = 3\n",
        "strides = 1\n",
        "layer_filters = [32,64,128,256]\n",
        "dnn_units = [latent_dim,1000,500,100]\n",
        "output_unit = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-gieE4FWodj",
        "colab_type": "code",
        "outputId": "694ed356-f4f8-4431-a8f6-f5d91c3ec80c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        }
      },
      "source": [
        "inputs = keras.layers.Input(shape=input_shape,name='Input')\n",
        "conv = inputs\n",
        "for filters in layer_filters:\n",
        "  conv = keras.layers.Conv2D(filters=filters,kernel_size=kernal_size,kernel_initializer='he_uniform', strides=strides,padding='same')(conv)\n",
        "  conv = keras.layers.LeakyReLU(alpha=0.3)(conv)\n",
        "  conv = keras.layers.AveragePooling2D(pool_size=(2,2))(conv)\n",
        "  conv = keras.layers.BatchNormalization()(conv)\n",
        "\n",
        "# Shape info needed to build Decoder Model\n",
        "shape = K.int_shape(conv)\n",
        "\n",
        "flat = keras.layers.Flatten()(conv)\n",
        "latent = keras.layers.Dense(units=latent_dim, name='Latent_vector')(flat)\n",
        "encoder = keras.models.Model(inputs,latent,name='encoder')\n",
        "print (\"Encoder Model\")\n",
        "print(encoder.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0826 10:48:56.031989 139861901346688 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Encoder Model\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input (InputLayer)           [(None, 32, 32, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        320       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 16, 16, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_3 (Average (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "Latent_vector (Dense)        (None, 1000)              1025000   \n",
            "=================================================================\n",
            "Total params: 1,414,760\n",
            "Trainable params: 1,413,800\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bznl-ql3W7XG",
        "colab_type": "code",
        "outputId": "6d0ca0e8-ea04-49b5-e0ba-701ae7ce87e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "#Create fully connected layer\n",
        "\n",
        "dnn_input = keras.layers.Input(shape=latent_dim,name='dnn_input')\n",
        "dnn = dnn_input\n",
        "for units in dnn_units:\n",
        "  dnn = keras.layers.Dense(units=units,kernel_initializer='he_uniform')(dnn)\n",
        "  dnn = keras.layers.Dropout(rate=0.2)(dnn)\n",
        "  dnn = keras.layers.LeakyReLU(alpha=0.3)(dnn)\n",
        "  dnn = keras.layers.BatchNormalization()(dnn)\n",
        "\n",
        "dnn_output = keras.layers.Dense(units=output_unit,kernel_initializer='he_uniform',activation='softmax')(dnn)\n",
        "dnn_model = keras.models.Model(inputs=dnn_input,outputs=dnn_output,name='dnn_model')\n",
        "print (\"DNN Model\")\n",
        "print (dnn_model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DNN Model\n",
            "Model: \"dnn_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dnn_input (InputLayer)       [(None, 1000)]            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 500)               2000      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               50100     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 2,564,010\n",
            "Trainable params: 2,558,810\n",
            "Non-trainable params: 5,200\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OHgcB0j9Uc1",
        "colab_type": "code",
        "outputId": "f8071d81-735e-477b-f785-56e52f077f77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "#Create ConvNet Model  = encoder + dnn_model\n",
        "cnn_model = keras.models.Model(inputs=inputs,outputs=dnn_model(encoder(inputs)),name='CNN_Model')\n",
        "cnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"CNN_Model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input (InputLayer)           [(None, 32, 32, 1)]       0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 1000)              1414760   \n",
            "_________________________________________________________________\n",
            "dnn_model (Model)            (None, 10)                2564010   \n",
            "=================================================================\n",
            "Total params: 3,978,770\n",
            "Trainable params: 3,972,610\n",
            "Non-trainable params: 6,160\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BVrUBe5eSCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.compile(optimizer='adam',loss ='categorical_crossentropy',metrics = ['accuracy'])\n",
        "#autoencoder.compile(optimizer='adam',loss ='mse',metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5dbc0520-0a21-47bb-a656-9a3ddfb1f8e7",
        "id": "V1lQuAyYeQpV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "      featurewise_std_normalization=True,\n",
        "      samplewise_std_normalization = False,\n",
        "      rotation_range=30,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      horizontal_flip=False,\n",
        "      vertical_flip=False,\n",
        "      fill_mode='nearest',\n",
        "      zoom_range=0.2,\n",
        "      zca_whitening=False\n",
        "      )\n",
        "\n",
        "train_datagen.fit(X_train_nn)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:348: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJPPtiuq76Nl",
        "colab_type": "code",
        "outputId": "0513e53e-6697-4bf9-e5b8-3abd4d98a07c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "DataGen = False\n",
        "for i in range (1):\n",
        "  if DataGen:\n",
        "    cnn_model.fit_generator(train_datagen.flow(X_train_nn, y_train_nn,batch_size=32),\n",
        "                      epochs=5, \n",
        "                      steps_per_epoch= X_train_nn.shape[0]/32,\n",
        "                      validation_data=(X_test_nn, y_test_nn),\n",
        "                      callbacks=[])\n",
        "    \n",
        "  else:\n",
        "    print (\"Training without agumentation\")\n",
        "    cnn_model.fit(X_train_nn,y_train_nn,\n",
        "          batch_size=32,\n",
        "          epochs=5,\n",
        "          validation_data=(X_test_nn,y_test_nn),\n",
        "          )\n",
        "\n",
        "  cnn_model.save('cnn_model.h5')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training without agumentation\n",
            "Train on 42000 samples, validate on 18000 samples\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 46s 1ms/sample - loss: 0.0085 - acc: 0.9971 - val_loss: 0.5143 - val_acc: 0.9244\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 46s 1ms/sample - loss: 0.0093 - acc: 0.9973 - val_loss: 0.5346 - val_acc: 0.9211\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 46s 1ms/sample - loss: 0.0078 - acc: 0.9977 - val_loss: 0.5140 - val_acc: 0.9231\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 45s 1ms/sample - loss: 0.0089 - acc: 0.9975 - val_loss: 0.5067 - val_acc: 0.9251\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 46s 1ms/sample - loss: 0.0096 - acc: 0.9971 - val_loss: 0.5381 - val_acc: 0.9254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RPDjWknKE_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_nn = cnn_model.predict(X_val_nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iquAcCD2G23W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_argmax = [np.argmax(x) for x in y_pred_nn]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC3OneryGiv_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "458b2783-d4d3-4257-d3af-01fdcdd6967e"
      },
      "source": [
        "print (classification_report(y_val,y_pred_argmax))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      6000\n",
            "           1       0.98      0.97      0.97      6000\n",
            "           2       0.99      0.98      0.98      6000\n",
            "           3       0.97      0.97      0.97      6000\n",
            "           4       0.98      0.98      0.98      6000\n",
            "           5       0.97      0.98      0.98      6000\n",
            "           6       0.97      0.97      0.97      6000\n",
            "           7       0.98      0.98      0.98      6000\n",
            "           8       0.98      0.97      0.97      6000\n",
            "           9       0.98      0.97      0.98      6000\n",
            "\n",
            "    accuracy                           0.98     60000\n",
            "   macro avg       0.98      0.98      0.98     60000\n",
            "weighted avg       0.98      0.98      0.98     60000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn9Swx9gGyk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inference\n",
        "# KNN algorithm took around 30 minutes train on 40,000 records and predict on 18,000 that too with very bad accuracy of 53%\n",
        "# The NN model tool much lesser time - and reached accuracy 98% in less than 50 iterations. This model was able to prodict the validation data correctly with 98% accuracy\n",
        "# We can clearly see that not only the neural network model takes muchg lesser time to learn such complex data but also is able to provide very high accuracy  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}